{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eb80815-06d6-4804-9046-409adeb6a7e3",
   "metadata": {},
   "source": [
    "idea what the data could look like\n",
    "(17890902, {'nom': 'Conseils Generaux', 'ville': 'versaille', 'sequenceHistorique': ''})\n",
    "(timestamp1, {'a':False, 'b':False, 'c':False}),\n",
    "(timestamp2, {'a':False, 'b':True, 'c':False}),\n",
    "(timestamp3, {'a':False, 'b':False, 'c':False}), \n",
    "(timestamp4, {'a':False, 'b':True, 'c':False}),\n",
    "https://stackoverflow.com/questions/38465620/looking-for-an-efficient-way-to-store-history-data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820f7070-569d-47f7-bc83-a710300f71f5",
   "metadata": {},
   "source": [
    "### 1) RECUPERATION DU CONTENU DE LA PAGE WIKIPEDIA <br>\n",
    "https://fr.wikipedia.org/wiki/Chronologie_de_la_R%C3%A9volution_fran%C3%A7aise <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33d4cd86-24b6-414b-b071-b74772ed51a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les modules nécessaires\n",
    "import requests\n",
    "\n",
    "# Récupérer l'Url\n",
    "r = requests.get(\"https://fr.wikipedia.org/wiki/Chronologie_de_la_R%C3%A9volution_fran%C3%A7aise\")\n",
    "\n",
    "# Enregistrer le contenu dans un fichier\n",
    "with open(\"response.html\", \"w\") as f:\n",
    "    f.write(r.text)\n",
    "    f.close() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32fb1b1a-6b38-43bf-b5a1-283dc3123002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les modules nécessaires\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "# Lire le fichier contenant le contenu\n",
    "with open(\"response.html\", \"r\") as f:\n",
    " \n",
    "# Parser l'html pour récupérer les <h2>, <h3> et <li> visés\n",
    "    soup = BeautifulSoup(f, 'html.parser')\n",
    "\n",
    "periode = []\n",
    "annee = []\n",
    "dateEtEvenement = []\n",
    "dates = soup.find(class_=\"mw-body-content\").find_all(\"li\", class_=False)\n",
    "for date in dates:\n",
    "    if date.find_previous(\"h3\") == None:\n",
    "        periode.append(date.find_previous(\"h2\").text)\n",
    "        annee.append(0)\n",
    "        dateEtEvenement.append(date.text)\n",
    "    else:\n",
    "        periode.append(date.find_previous(\"h2\").text)\n",
    "        annee.append(date.find_previous(\"h3\").text)\n",
    "        dateEtEvenement.append(date.text)\n",
    "\n",
    "# Sauvegarder les fichiers\n",
    "with open(\"periode.json\", \"w\") as f:\n",
    "    json.dump(periode, f)\n",
    "    f.close() \n",
    "with open(\"annee.json\", \"w\") as f:\n",
    "    json.dump(annee, f)\n",
    "    f.close() \n",
    "with open(\"dateEtEvenement.json\", \"w\") as f:\n",
    "    json.dump(dateEtEvenement, f)\n",
    "    f.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3e0522-cda2-4c45-99b0-1e13c6ef942e",
   "metadata": {},
   "source": [
    "### 2) NETTOYAGE DES DONNEES <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "187dc416-58f2-4852-92c3-1918cfb306b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unconverted data remains when parsing with format \"%B\": \" \", at position 0. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvenement\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdateEtEvenement\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m, n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, expand \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     21\u001b[0m df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mday\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit( n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, expand \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 22\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmois\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmonth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mB\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#df[\"mois\"] = pd.to_datetime(df[\"month\"])\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#df[\"date\"] = pd.to_datetime(df[\"date\"])\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#df[\"level\"] = [np.random.randint(-6,-2) if (i%2)==0 else np.random.randint(2,6) for i in range(len(df))]\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m#print(df.head())\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#df2 = df.head()\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m>>> from datetime import datetime\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m>>> datetime.strptime('Jan', '%b')\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03mdf['month_year'] = pd.to_datetime(df.Month, format='%B').dt.month.astype(str) +\"_\"+ df.Year\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyter_env/lib/python3.12/site-packages/pandas/core/tools/datetimes.py:1063\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1061\u001b[0m             result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mtz_localize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, ABCSeries):\n\u001b[0;32m-> 1063\u001b[0m     cache_array \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_listlike\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cache_array\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m   1065\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyter_env/lib/python3.12/site-packages/pandas/core/tools/datetimes.py:247\u001b[0m, in \u001b[0;36m_maybe_cache\u001b[0;34m(arg, format, cache, convert_listlike)\u001b[0m\n\u001b[1;32m    245\u001b[0m unique_dates \u001b[38;5;241m=\u001b[39m unique(arg)\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_dates) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(arg):\n\u001b[0;32m--> 247\u001b[0m     cache_dates \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43munique_dates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;66;03m# GH#45319\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyter_env/lib/python3.12/site-packages/pandas/core/tools/datetimes.py:433\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64(\n\u001b[1;32m    436\u001b[0m     arg,\n\u001b[1;32m    437\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    441\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    442\u001b[0m )\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyter_env/lib/python3.12/site-packages/pandas/core/tools/datetimes.py:467\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[0;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_array_strptime_with_fallback\u001b[39m(\n\u001b[1;32m    457\u001b[0m     arg,\n\u001b[1;32m    458\u001b[0m     name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    462\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    463\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[1;32m    464\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;124;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 467\u001b[0m     result, tz_out \u001b[38;5;241m=\u001b[39m \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tz_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    469\u001b[0m         unit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime_data(result\u001b[38;5;241m.\u001b[39mdtype)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32mstrptime.pyx:501\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mstrptime.pyx:451\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mstrptime.pyx:587\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime._parse_with_format\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: unconverted data remains when parsing with format \"%B\": \" \", at position 0. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "# Importer les modules nécessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import locale\n",
    "locale.setlocale(locale.LC_ALL, 'fr_FR.UTF-8')\n",
    "#print(locale.setlocale(locale.LC_ALL, ''))\n",
    "\n",
    "# Lire les jsons et récupérer les listes\n",
    "with open(\"periode.json\", \"r\") as f:\n",
    "    periode = json.load(f)\n",
    "with open(\"annee.json\", \"r\") as f:\n",
    "    annee = json.load(f)\n",
    "with open(\"dateEtEvenement.json\", \"r\") as f:\n",
    "    dateEtEvenement = json.load(f)\n",
    "    \n",
    "# Construire le dataframe \n",
    "df = pd.DataFrame ({'Période': periode, 'Année': annee, 'dateEtEvenement': dateEtEvenement})\n",
    "\n",
    "df[[\"date\",\"Evenement\"]] = df[\"dateEtEvenement\"].str.split(\":\", n = 1, expand = True)\n",
    "df[[\"day\",\"month\"]] = df[\"date\"].str.split( n = 1, expand = True)\n",
    "df[\"mois\"] = pd.to_datetime(df[\"month\"], format=\"%B\")\n",
    "\n",
    "#df[\"mois\"] = pd.to_datetime(df[\"month\"])\n",
    "#df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "#df[\"level\"] = [np.random.randint(-6,-2) if (i%2)==0 else np.random.randint(2,6) for i in range(len(df))]\n",
    "\n",
    "#print(df.head())\n",
    "#df2 = df.head()\n",
    "\"\"\"\n",
    ">>> from datetime import datetime\n",
    ">>> datetime.strptime('Jan', '%b')\n",
    "\n",
    "df['month_year'] = pd.to_datetime(df.Month, format='%B').dt.month.astype(str) +\"_\"+ df.Year\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a7b67c-389d-4d39-b6df-21d61fc14d4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07b6d34-af6e-4cad-9d5a-60763929d4a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb57db12-5e10-4d6e-8b9e-195c505b3d4d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Récupérer les index à supprimer\n",
    "toDrop = df.loc[(df['Période'] == 'Notes et références') | (df['Période'] == 'Voir aussi')].index\n",
    "df2 = df.drop(toDrop)\n",
    "#print(df2.head(10))\n",
    "#print(df2.tail(10))\n",
    "#print(df2.dtypes)\n",
    "#print(df2.describe())\n",
    "#print(df2.info())\n",
    "\n",
    "df2 = df2.drop([df2.index[193]                                    \n",
    ",df2.index[194]                     \n",
    ",df2.index[319]                            \n",
    ",df2.index[320]                               \n",
    ",df2.index[454]  \n",
    ",df2.index[489]           \n",
    ",df2.index[502]                       \n",
    ",df2.index[504]])\n",
    "\n",
    "#print(df2)\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "toDrop = df2.loc[(df2['dateEtEvenement'].str.contains('Liste'))].index\n",
    "df2 = df2.drop(toDrop)\n",
    "#print(df2.head(10))\n",
    "#print(df2.tail(10))\n",
    "#print(df2.dtypes)\n",
    "#print(df3.describe())\n",
    "#print(df3.info())\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "toDrop = df3.loc[(~df3['dateEtEvenement'].str.contains(r'(.*?):'))] #.index\n",
    "#print(toDrop)\n",
    "#df3 = df2.drop(toDrop)\n",
    "#print(df2.head(10))\n",
    "#print(df2.tail(10))\n",
    "#print(df2.dtypes)\n",
    "#print(df3.describe())\n",
    "#print(df3.info())\n",
    "\n",
    "dfGood = df3.loc[(df3['dateEtEvenement'].str.contains(r'(.*?):'))] #.index\n",
    "#print(dfGood)\n",
    "\n",
    "dfBad = df3.loc[(~df3['dateEtEvenement'].str.contains(r'(.*?):'))] #.index\n",
    "print(dfBad)\n",
    "\n",
    "\n",
    "12 septembre 1793 : \n",
    "bataille d'Avesnes-le-Sec (en)\n",
    "combat d'Haspres \n",
    "\n",
    "\n",
    "19 septembre : \n",
    "319                          bataille du Pont-Barré[7]  \n",
    "320                              bataille de Torfou[7] \n",
    "\n",
    "\n",
    "193                                   combat d'Haspres  \n",
    "194                     bataille d'Avesnes-le-Sec (en)  \n",
    "319                          bataille du Pont-Barré[7]  \n",
    "320                              bataille de Torfou[7]  \n",
    "454  En février on conseille à Bonaparte de porter ...  \n",
    "489           6 - 7 novembre bataille de Calliano (en)  \n",
    "502                        Expédition d'Irlande (1796)  \n",
    "504                        Expédition d'Irlande (1798)  \n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "for i in df2['dateEtEvenement']: \n",
    "    if i.count(\":\") == 2:\n",
    "        print(i)\n",
    "    if i.count(\":\") == 0:\n",
    "        print(i)\n",
    "\n",
    "    \n",
    "#find a way to split\n",
    "#print(df2['Date et Evènement'].str.split(' : ', n=1, expand=True))\n",
    "#df3.columns = ['column{}'.format(x+1) for x in df3.columns]\n",
    "#print(df2)\n",
    "#print(df2['Date et Evènement'].str.split(' : ', 1).tolist(), columns = ['Date', 'Evènement'])\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "toDrop =[]\n",
    "for i in df2['dateEtEvenement']: \n",
    "    if i.count(\":\") == 2 | i.count(\":\") != 1 :\n",
    "        ind = df2.loc[(df2[i])].index\n",
    "        toDrop.append(ind)\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "for i in df2['dateEtEvenement']: \n",
    "    if i.count(\":\") != 1:\n",
    "        print(i)\n",
    "\"\"\"  \n",
    "\"\"\"\n",
    "print(toDrop)\n",
    "#df2 = df2.drop(toDrop)\n",
    " \"\"\"       \n",
    "df2[['First','Last']] = df2.dateEtEvenement.str.split(r\"(.*?):\", n=1) #REGEX IMPORTANT DETERMINER PREMIER :\n",
    "\n",
    "print(df2)\n",
    "#bug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a4db0c-9bf0-4919-b664-6b158e415ca1",
   "metadata": {},
   "source": [
    "Source : <br>\n",
    "https://www.geeksforgeeks.org/web-scraping-from-wikipedia-using-python-a-complete-guide/ <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f888f8-60d5-4fc8-af51-04b95dd9fd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "2) Save data in file <br>\n",
    "https://stackoverflow.com/questions/31126596/saving-response-from-requests-to-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b633340e-6b41-452d-b462-7e10a0e9d4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "3) Plot as a a timeline <br>\n",
    "https://matplotlib.org/stable/gallery/lines_bars_and_markers/timeline.html\n",
    "https://coderzcolumn.com/tutorials/data-science/timeline-using-matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb987f2d-c95a-4107-ac34-520cd5af68f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jupyter_env] *",
   "language": "python",
   "name": "conda-env-jupyter_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
